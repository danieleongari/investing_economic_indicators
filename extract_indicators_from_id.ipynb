{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract economic table and scrape informations for each indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import time\n",
    "sleep_time_sec = 1\n",
    "CHROME_OPTIONS = Options()\n",
    "CHROME_OPTIONS.add_argument('--no-sandbox')\n",
    "CHROME_OPTIONS.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve information from each page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Index: 200\n",
      " - URL: https://www.investing.com/economic-calendar/machine-tool-orders-200 \n",
      " - Name: machine tool orders\n",
      " - Country: Japan\n",
      " - Title: Japan Machine Tool Orders YoY\n",
      " - Source: Japan Machine Tool Builders' Association\n",
      " - Source_link: http://www.jmtba.or.jp/english/ \n",
      " - Currency: JPY\n",
      " - Importance: 1\n",
      " - Description: Machine Tool Orders measures the change in the total value of new orders placed with machine tool manufacturers. Two versions of this report are released, preliminary and final. The preliminary report had the biggest impact.A higher than expected reading should be taken as positive/bullish for the JPY, while a lower than expected reading should be taken as negative/bearish for the JPY.\n"
     ]
    }
   ],
   "source": [
    "# Use Selenium on the URL page to extract page-info\n",
    "def scrape_page(url):\n",
    "    blacklist = [\n",
    "        \"We're temporarily down for maintenance; Please check back soon...\" # Some pages take several seconds to load and then throw this error\n",
    "    ]\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    browser = webdriver.Chrome(service=service, options=CHROME_OPTIONS)\n",
    "    \n",
    "    try:\n",
    "        browser.get(url)\n",
    "    except:\n",
    "        print(f\"Skipped: {url} to browser.get(url) failure\")\n",
    "        res = {k: None for k in ['Title', 'Source', 'Source_link', 'Currency', 'Description']}\n",
    "        soup = None\n",
    "        return res, soup\n",
    "    \n",
    "    time.sleep(sleep_time_sec) # To leave the time for the page to load \n",
    "    html = browser.page_source\n",
    "    browser.close()\n",
    "    soup = bs(html,'html.parser')\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    res[\"Index\"] = int(url.split(\"/\")[-1])\n",
    "    \n",
    "    # Link to the source, e.g., adp-nonfarm-employment-change-1\n",
    "    link_tag = soup.find('link', rel='canonical')\n",
    "    \n",
    "    if not link_tag: # page not existing e.g., https://www.investing.com/economic-calendar/002\n",
    "        return res, None\n",
    "    \n",
    "    res[\"URL\"] = link_tag['href'] + \" \" # e.g., \"https://www.investing.com/economic-calendar/adp-nonfarm-employment-change-1 \" NOTE: leave a space at the end to make it clickable in the csv\n",
    "    res[\"Name\"] = res[\"URL\"].split(\"/\")[-1].rpartition('-')[0].replace(\"-\", \" \") # e.g., adp nonfarm employment change\n",
    "    \n",
    "    country_label = soup.find('span', string='Country:')\n",
    "    country_tag = country_label.find_next('i', class_='ceFlags')\n",
    "    res[\"Country\"] = country_tag['title']\n",
    "\n",
    "    res['Title'] = soup.find('title').text.strip()\n",
    "    if res['Title'] in blacklist:\n",
    "        print(f\"Skipped: {url} due to `{res['Title']}`\")\n",
    "        res = {k: None for k in ['Title', 'Source', 'Source_link', 'Currency', 'Description']}\n",
    "        return res, soup\n",
    "\n",
    "    source_span = soup.find('span', string='Source:')\n",
    "    res['Source'] = source_span.find_next_sibling('span').find('a')['title']\n",
    "    res['Source_link'] = source_span.find_next_sibling('span').find('a')['href'] + \" \" # NOTE: leave a space at the end to make it clickable in the csv\n",
    "\n",
    "    curr_span = soup.find('span', string='Currency:')\n",
    "    res['Currency'] = curr_span.find_next_sibling('span').text\n",
    "    \n",
    "    stars = soup.find_all('i', class_='grayFullBullishIcon')\n",
    "    res[\"Importance\"] = len(stars)\n",
    "\n",
    "    overViewBox_div = soup.find('div', class_='overViewBox')\n",
    "    overViewBox_left = overViewBox_div.find('div', class_='left')\n",
    "    if overViewBox_left:\n",
    "        res['Description'] = (\n",
    "            overViewBox_left\n",
    "            .get_text()\n",
    "            .replace(\"<br>\", \" \")\n",
    "            .replace(\"\\n\", \" \")\n",
    "        )\n",
    "    else:\n",
    "        res['Description'] = None\n",
    "\n",
    "    return res, soup\n",
    "\n",
    "# Test\n",
    "url = \"https://www.investing.com/economic-calendar/200\"\n",
    "res, soup = scrape_page(url)\n",
    "for k, v in res.items():\n",
    "    print(f\" - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.investing.com/economic-calendar/adp-nonfarm-employment-change-1  scraped\n",
      "https://www.investing.com/economic-calendar/002 failed to scrape\n",
      "https://www.investing.com/economic-calendar/003 failed to scrape\n",
      "https://www.investing.com/economic-calendar/all-industries-activity-index.-4  scraped\n",
      "https://www.investing.com/economic-calendar/anz-commodity-price-index-5  scraped\n",
      "https://www.investing.com/economic-calendar/average-cash-earnings-6  scraped\n",
      "https://www.investing.com/economic-calendar/average-earnings-index-bonus-7  scraped\n",
      "https://www.investing.com/economic-calendar/average-hourly-earnings-8  scraped\n",
      "https://www.investing.com/economic-calendar/gross-mortgage-approvals-9  scraped\n",
      "https://www.investing.com/economic-calendar/beige-book-10  scraped\n",
      "https://www.investing.com/economic-calendar/boc-review-11  scraped\n",
      "https://www.investing.com/economic-calendar/boc-deputy-governor-duguay-speaks-12  scraped\n",
      "https://www.investing.com/economic-calendar/boc-deputy-governor-jenkins-speaks-13  scraped\n",
      "Skipped: https://www.investing.com/economic-calendar/014 to browser.get(url) failure\n",
      "https://www.investing.com/economic-calendar/014 failed to scrape\n",
      "https://www.investing.com/economic-calendar/boe-inflation-report-15  scraped\n",
      "https://www.investing.com/economic-calendar/boe-official-jenkinson-speaks-16  scraped\n"
     ]
    }
   ],
   "source": [
    "filename = \"economic_indicators.csv\"\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['Index', 'URL', 'Name', 'Country', 'Title', 'Source', 'Source_link', 'Importance', 'Currency', 'Description'])\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "for i in range(1, 1000):\n",
    "    url = f\"https://www.investing.com/economic-calendar/{i:03d}\"\n",
    "    \n",
    "    row = df[df['Index'] == i]\n",
    "    if row.shape[0] > 0:\n",
    "        if pd.isna(row['URL'].values[0]):\n",
    "            print(f\"{url} failed to scrape\")\n",
    "        else:\n",
    "            print(f\"{url} already scraped as {row['URL'].values[0]}\")\n",
    "        continue\n",
    "    \n",
    "    res, soup = scrape_page(url)\n",
    "    df = pd.concat([df, pd.DataFrame.from_records([res])]) # Equivalent to df.append(res, ignore_index=True)\n",
    "    df.to_csv(filename, index=False)\n",
    "    if \"URL\" in res:\n",
    "        print(f\"{res['URL']} scraped\")\n",
    "    else:\n",
    "        print(f\"{url} failed to scrape\")\n",
    "    time.sleep(sleep_time_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAke the README\n",
    "readme_text = \"\"\"# Investing.com Economic Indicators\n",
    "\n",
    "List of all the economic indicators from [Investing.com](https://www.investing.com/).\n",
    "\n",
    "Available as a [CSV table](economic_indicators.csv).\n",
    "\"\"\"\n",
    "\n",
    "readme_text += \"\\n## Most Important Indicators (three stars)\\n\\n\"\n",
    "\n",
    "filename = \"economic_indicators.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df = df.sort_values(by=['Country', 'Index'], ascending=True)\n",
    "\n",
    "for i, row in df[df['Importance'] == 3].iterrows():\n",
    "    readme_text += f\"1. [{row['Country']} - {row['Title']}]({row['URL'].strip()})\\n\"\n",
    "    \n",
    "readme_text += \"\\n## Middle Importance Indicators (two stars)\\n\\n\"\n",
    "\n",
    "for i, row in df[df['Importance'] == 2].iterrows():\n",
    "    readme_text += f\"1. [{row['Country']} - {row['Title']}]({row['URL'].strip()})\\n\"\n",
    "    \n",
    "readme_text += \"\\n## Least Important Indicators (one star)\\n\\n\"\n",
    "\n",
    "for i, row in df[df['Importance'] == 1].iterrows():\n",
    "    readme_text += f\"1. [{row['Country']} - {row['Title']}]({row['URL'].strip()})\\n\"\n",
    "\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(readme_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2540cd9198af0b9eaea5a5cb83e008828d2d08e9e651b172f5d346fcf048848a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
